{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d5f3434-d8d4-440a-8d19-2f333622c081",
   "metadata": {},
   "source": [
    "# Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b36fb2b7-fe60-4897-ba7c-aabb9274aa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from PIL import Image, ImageTk\n",
    "from sklearn.preprocessing import normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e7eb4b-24e9-4a55-9a13-37aa71f6aaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2: Used for computer vision tasks such as face detection and face recognition.\n",
    "# numpy: Provides support for working with arrays.\n",
    "# tkinter: Standard Python library to build graphical user interfaces.\n",
    "# PIL (Python Imaging Library): Used for opening, manipulating, and converting image formats, particularly useful in conjunction with Tkinter.\n",
    "# sklearn.preprocessing.normalize: Used to normalize face images (although not used in the current version)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4f8fe7-eae8-4e92-b302-f4eac7d0df52",
   "metadata": {},
   "source": [
    "# Initialize Known Faces and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48f89789-81b2-4131-baf5-76d6683d34d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded_images = ['ref1.jpg','ref2.jpg','r3.jpg']\n",
    "known_face_labels = []\n",
    "known_face_images = []\n",
    "mnx=[\"Elon musk\",\"mark zuckerberg\",\"Sunder pichai\"]\n",
    "confidence_threshold = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c97dddd5-ae30-455f-99fa-c9df2818efa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uploaded_images: List of image file names of the people you want to recognize.\n",
    "# known_face_labels: Empty list to store labels (used to identify which person the face belongs to).\n",
    "# known_face_images: Empty list to store cropped face images.\n",
    "# mnx: List of corresponding names for each face in uploaded_images.\n",
    "# confidence_threshold: Threshold for face recognition. Lowering the value makes the recognition stricter (lower tolerance for mismatches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fde2aee-d755-4e83-bf04-4038091dbbe4",
   "metadata": {},
   "source": [
    "# Initialize Face Cascade for Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24c4c841-986b-47f4-a921-6b057bbd5c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "167e31a7-66be-4d24-b506-067543d42309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CascadeClassifier: Loads the pre-trained Haar cascade for frontal face detection, which is provided by OpenCV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e508a1c-40ab-403a-9a19-fdfd1ebccbee",
   "metadata": {},
   "source": [
    "# Preprocess the Face Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "802d211e-bde4-464d-a2f6-568ef1b15681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.equalizeHist(image)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e5f5efb-7e7a-4057-966e-03bc2e6bb7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to grayscale: Converts the image to grayscale if itâ€™s in color.\n",
    "# Histogram Equalization: Adjusts the contrast of the grayscale image to improve the face detection and recognition accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3d2b62-b2eb-4445-9c8e-670643a8c551",
   "metadata": {},
   "source": [
    "# Load Images and Train the Face Recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "912ea514-6eae-4868-9239-626cb13f2964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_and_train():\n",
    "    global face_recognizer\n",
    "    for idx, img_path in enumerate(uploaded_images):\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if image is None:\n",
    "            print(f\"Error: Could not load image {img_path}\")\n",
    "            continue\n",
    "        image = preprocess_image(image)\n",
    "        faces = face_cascade.detectMultiScale(image, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "        for (x, y, w, h) in faces:\n",
    "            face = image[y:y+h, x:x+w]\n",
    "            known_face_images.append(face)\n",
    "            known_face_labels.append(idx)\n",
    "    if not known_face_images:\n",
    "        messagebox.showerror(\"Error\", \"No faces found in uploaded images.\")\n",
    "        return\n",
    "    \n",
    "    face_recognizer.train(known_face_images, np.array(known_face_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc014cc3-2dea-40c6-8eb6-25a21c455fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function loops through the uploaded_images, converts them to grayscale, and detects faces using detectMultiScale().\n",
    "# Each detected face is cropped and stored in known_face_images.\n",
    "# The face label (index from mnx) is stored in known_face_labels.\n",
    "# After processing, the function uses face_recognizer.train() to train the recognizer on the labeled images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc69a9d6-ab59-4421-a7bb-a1c103478937",
   "metadata": {},
   "source": [
    "# Start Camera and Recognize Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ac349dd-bcd6-40c3-9903-0f22e96a2f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_camera():\n",
    "    global cap\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        messagebox.showerror(\"Error\", \"Could not open camera.\")\n",
    "        return\n",
    "    \n",
    "    def update_frame():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            messagebox.showerror(\"Error\", \"Could not read frame.\")\n",
    "            return\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "        for widget in faces_frame.winfo_children():\n",
    "            widget.destroy()\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            face = gray_frame[y:y+h, x:x+w]\n",
    "            face = preprocess_image(face)\n",
    "            label, confidence = face_recognizer.predict(face)\n",
    "            if confidence < confidence_threshold:\n",
    "                name = mnx[label]\n",
    "                cv2.putText(frame, f\"{name} ({round(confidence, 2)})\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "            else:\n",
    "                cv2.putText(frame, \"Not Matched\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "            detected_face = frame[y:y+h, x:x+w]\n",
    "            detected_face = cv2.resize(detected_face, (100, 100))\n",
    "            detected_face = cv2.cvtColor(detected_face, cv2.COLOR_BGR2RGB)\n",
    "            face_img = Image.fromarray(detected_face)\n",
    "            face_imgtk = ImageTk.PhotoImage(image=face_img)\n",
    "            face_label = tk.Label(faces_frame, image=face_imgtk)\n",
    "            face_label.image = face_imgtk\n",
    "            face_label.pack(side='left', padx=10)\n",
    "\n",
    "        cv2image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img = Image.fromarray(cv2image)\n",
    "        imgtk = ImageTk.PhotoImage(image=img)\n",
    "        camera_label.imgtk = imgtk\n",
    "        camera_label.configure(image=imgtk)\n",
    "        camera_label.after(10, update_frame)\n",
    "\n",
    "    update_frame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a278535a-74d3-4b6e-b55d-39f3098cd070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Camera: Attempts to open the camera feed using VideoCapture(0).\n",
    "# Process Each Frame: Converts each frame to grayscale, detects faces, and matches them using the face recognizer.\n",
    "# Display Faces and Names: Detected faces are drawn on the frame with a rectangle, and the name of the person is written if recognized.\n",
    "# Tkinter Update: The update_frame function continuously updates the Tkinter GUI with the live video feed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3686f94a-5edf-4a34-b374-a90a9d3d4e22",
   "metadata": {},
   "source": [
    "# Stop Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5929d1f2-5e34-491c-b699-a8e75e195776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_camera():\n",
    "    global cap\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    camera_label.config(image='')\n",
    "    for widget in faces_frame.winfo_children():\n",
    "        widget.destroy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6d49421-d15a-4583-bb45-f4b39d3a19ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Releases the camera and clears the video feed displayed in the GUI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e64e1f8-4e38-4a20-bf2a-4d25be57df54",
   "metadata": {},
   "source": [
    "# Upload a New Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c33c6922-2d7a-4181-a709-0b8a3e504cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_image():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        new_image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if new_image is None:\n",
    "            messagebox.showerror(\"Error\", \"Invalid image format\")\n",
    "            return\n",
    "        \n",
    "        new_image = preprocess_image(new_image)\n",
    "        faces = face_cascade.detectMultiScale(new_image, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "        if len(faces) == 0:\n",
    "            messagebox.showerror(\"Error\", \"No face detected in the image.\")\n",
    "            return\n",
    "        \n",
    "        for (x, y, w, h) in faces:\n",
    "            face = new_image[y:y+h, x:x+w]\n",
    "            known_face_images.append(face)\n",
    "            known_face_labels.append(len(mnx))\n",
    "            mnx.append(f\"Person {len(mnx) + 1}\")\n",
    "        face_recognizer.train(known_face_images, np.array(known_face_labels))\n",
    "        messagebox.showinfo(\"Success\", \"New face added and recognizer updated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18780625-6b07-4ec3-93bd-34dbe16bb06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allows users to add new faces to the recognizer by uploading an image. The new face is detected, processed, and added to the list of known faces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9bb505-b07e-4525-bf69-bf97bf192dc9",
   "metadata": {},
   "source": [
    "# GUI Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3b498e3-8b1e-48e7-9689-b66c5fb1b018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not load image ref2.jpg\n"
     ]
    }
   ],
   "source": [
    "root = tk.Tk()\n",
    "root.title(\"Face Recognition\")\n",
    "root.geometry(\"1000x700\")\n",
    "root.configure(bg='#f0f0f0')\n",
    "\n",
    "camera_label = tk.Label(root, text=\"Camera Feed\", bg='#f0f0f0', fg='#333', font=('Arial', 12))\n",
    "camera_label.pack(pady=10)\n",
    "\n",
    "faces_frame = tk.Frame(root, bg='#f0f0f0')\n",
    "faces_frame.pack(pady=10)\n",
    "\n",
    "control_frame = tk.Frame(root, bg='#f0f0f0')\n",
    "control_frame.pack(pady=20)\n",
    "\n",
    "start_button = tk.Button(control_frame, text=\"Start Camera\", command=start_camera, bg='#4CAF50', fg='white', font=('Arial', 12), padx=10, pady=5)\n",
    "start_button.grid(row=0, column=0, padx=10)\n",
    "\n",
    "stop_button = tk.Button(control_frame, text=\"Stop Camera\", command=stop_camera, bg='#f44336', fg='white', font=('Arial', 12), padx=10, pady=5)\n",
    "stop_button.grid(row=0, column=1, padx=10)\n",
    "\n",
    "upload_button = tk.Button(control_frame, text=\"Upload Image\", command=upload_image, bg='#2196F3', fg='white', font=('Arial', 12), padx=10, pady=5)\n",
    "upload_button.grid(row=0, column=2, padx=10)\n",
    "face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "load_images_and_train()\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ea7668-0755-4daa-8170-534ec9c36c56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
